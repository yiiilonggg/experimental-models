{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational AutoEncoder Chess Position Generator\n",
    "\n",
    "##### Inspiration\n",
    "* Recently, I have been reading up about generative models, and one of them that caught my eye was the VAE.\n",
    "* It allows you to generate new data that is similar to your training data.\n",
    "* At the same time, I am interested in chess and have enjoyed solving chess puzzles for quite awhile.\n",
    "* However, the premise of a chess puzzle is that the player knows that there exists a optimal move / sequence of moves that provides the player an advantage.\n",
    "* This helps the player to improve in terms of tactics and pattern recognition, but in most cases when playing a game of chess, we do not know if there exists an optimal solution.\n",
    "* This introduces the idea of an anti-puzzle, where the premise is now that the chess position provided may have an optimal solution, or the \"solution\" is to play a move that maintains the status-quo.\n",
    "* With the VAE, we can train it with a training set of legal chess positions, and have it output more chess positions.\n",
    "* Since the VAE would not have any idea if the chess position has an optimal solution or not, it is perfect for creating \"anti-puzzle\" solutions.\n",
    "* Furthermore, chess is a \"constrained\" game, where the rules are clear and we can check if the position generated by the VAE is a legal position or not.\n",
    "* For this model, the goal is to simply generate new (legal) chess positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-02 03:00:48.642752: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pprint\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from scipy.stats import norm\n",
    "from keras import layers, models, metrics, losses, optimizers, activations\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import KFold, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Collection\n",
    "\n",
    "* The easiest way to obtain chess is positions is from my own games.\n",
    "* I exported move data from some chess games that I have played online in Lichess, which comes in a .pgn file.\n",
    "* From this file, we can get the move orders for the games that I have exported, from which I can deduce the chess positions.\n",
    "* For this, I used the python-chess library, which helps to deduce FEN positions from PGN move list\n",
    "* Once we get the FEN positions, we can derive the values for the input data we wish to parse into our model\n",
    "\n",
    "##### Data Representation\n",
    "* Although this doesn't give the chess positions directly, we can manipulate it into a form that works for the VAE.\n",
    "* The current idea is to have a 8 x 8 x 12 matrix, which means to say each of the 12 pieces (K, Q, R, B, N, P, k, q, r, b, n, p) each have their own 8 x 8 chessboard that denotes their position.\n",
    "* We can generate these as all chess games I exported start from the standard position, and we can denote the piece at a certain position with a 1 (i.e. 0 marks that the piece is not at that position).\n",
    "* This coincidentally is a perfect data set for generating anti-puzzles as it is formed from the sequence of moves of a game, of which not all positions have an optimal solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = os.path.dirname(__vsc_ipynb_file__)\n",
    "fen_data_path = os.path.join(DIR, \"data\", \"fen-data.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIECE_TO_IDX = dict([[c, i] for i, c in enumerate('KQRBNPkqrbnp')])\n",
    "\n",
    "def generate_matrix_from_fen(fen_string):\n",
    "    # initialise board\n",
    "    board = [[[0 for k in range(12)] for j in range(8)] for i in range(8)]\n",
    "    feature = [0 for i in range(12)]\n",
    "\n",
    "    # process FEN string\n",
    "    board_string = fen_string.split(\" \")[0].split(\"/\")\n",
    "    row, col = 0, 0\n",
    "    for board_row in board_string:\n",
    "        for row_item in board_row:\n",
    "            if row_item.isnumeric():\n",
    "                col += int(row_item)\n",
    "            else:\n",
    "                board[row][col][PIECE_TO_IDX[row_item]] = 1\n",
    "                feature[PIECE_TO_IDX[row_item]] += 1\n",
    "                col += 1\n",
    "        row += 1\n",
    "        col = 0\n",
    "\n",
    "    feature = [f / 8 for f in feature]\n",
    "    \n",
    "    return board, feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(141285, 8, 8, 13)\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "with open(fen_data_path) as file:\n",
    "    for line in file:\n",
    "        board, feature = generate_matrix_from_fen(line)\n",
    "        feature = np.array(feature, 'float64')\n",
    "        feature.resize((8, 8, 1))\n",
    "        board = np.array(board, 'float64')\n",
    "        curr = np.concatenate([board, feature], axis = 2)\n",
    "        data.append(curr)\n",
    "data = np.array(data, dtype = np.float64)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (hyper)parameters\n",
    "latent_dims = 8\n",
    "hidden_layers = 3\n",
    "base_units = 2 << 3\n",
    "kernel_size = (2, 2)\n",
    "strides = 2\n",
    "dropout_rate = 0.3\n",
    "threshold = 0.3\n",
    "beta_1 = 10 ** 4\n",
    "beta_2 = 10 ** -2\n",
    "learning_rate = 10 ** -3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)     [(None, 8, 8, 13)]   0           []                               \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 4, 4, 16)     848         ['encoder_input[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 4, 4, 16)    64          ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 4, 4, 16)     0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_30 (Dropout)           (None, 4, 4, 16)     0           ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 2, 2, 32)     2080        ['dropout_30[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 2, 2, 32)    128         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 2, 2, 32)     0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_31 (Dropout)           (None, 2, 2, 32)     0           ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 1, 1, 64)     8256        ['dropout_31[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 1, 1, 64)    256         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 1, 1, 64)     0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_32 (Dropout)           (None, 1, 1, 64)     0           ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 64)           0           ['dropout_32[0][0]']             \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 8)            520         ['flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 8)            520         ['flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " sampling_5 (Sampling)          (None, 8)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,672\n",
      "Trainable params: 12,448\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decoder_input (InputLayer)  [(None, 8)]               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                576       \n",
      "                                                                 \n",
      " reshape_5 (Reshape)         (None, 1, 1, 64)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_20 (Conv2D  (None, 2, 2, 64)         16448     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_33 (Bat  (None, 2, 2, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_33 (Activation)  (None, 2, 2, 64)          0         \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 2, 2, 64)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_21 (Conv2D  (None, 4, 4, 32)         8224      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_34 (Bat  (None, 4, 4, 32)         128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_34 (Activation)  (None, 4, 4, 32)          0         \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 4, 4, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_22 (Conv2D  (None, 8, 8, 16)         2064      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_35 (Bat  (None, 8, 8, 16)         64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_35 (Activation)  (None, 8, 8, 16)          0         \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 8, 8, 16)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_23 (Conv2D  (None, 8, 8, 13)         845       \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " tf.math.tanh_5 (TFOpLambda)  (None, 8, 8, 13)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,605\n",
      "Trainable params: 28,381\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape = (batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "class vae_chess(models.Model):\n",
    "\n",
    "    def __init__(self, latent_dims, hidden_layers, base_units, kernel_size, strides, dropout_rate, threshold, beta_1, beta_2):\n",
    "        super(vae_chess, self).__init__()\n",
    "\n",
    "        self.latent_dims = latent_dims\n",
    "        self.threshold = threshold\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "\n",
    "        self.encoder = self.generate_encoder_model(hidden_layers, base_units, kernel_size, strides, dropout_rate)\n",
    "        self.decoder = self.generate_decoder_model(hidden_layers, base_units, kernel_size, strides, dropout_rate)\n",
    "        print(self.encoder.summary())\n",
    "        print(self.decoder.summary())\n",
    "\n",
    "        self.total_loss_tracker = metrics.Mean(name = \"total_loss\")\n",
    "        self.reconstruction_loss_tracker = metrics.Mean(name = \"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = metrics.Mean(name = \"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.total_loss_tracker, self.reconstruction_loss_tracker, self.kl_loss_tracker]\n",
    "\n",
    "    def generate_encoder_model(self, hidden_layers, base_units, kernel_size, strides, dropout_rate):\n",
    "        encoder_input = layers.Input(shape = (8, 8, 13), name = \"encoder_input\")\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "            conv_layer = layers.Conv2D(base_units << i, kernel_size, strides, padding = \"same\")(encoder_input if i == 0 else dropout_layer)\n",
    "            batch_norm_layer = layers.BatchNormalization()(conv_layer)\n",
    "            activation_layer = layers.Activation('relu')(batch_norm_layer)\n",
    "            dropout_layer = layers.Dropout(dropout_rate)(activation_layer)\n",
    "        self.pass_back_shape = K.int_shape(dropout_layer)[1:]\n",
    "\n",
    "        flatten_layer = layers.Flatten()(dropout_layer)\n",
    "        z_mean = layers.Dense(self.latent_dims, name = \"z_mean\")(flatten_layer)\n",
    "        z_log_var = layers.Dense(self.latent_dims, name = \"z_log_var\")(flatten_layer)\n",
    "        z = Sampling()([z_mean, z_log_var])\n",
    "\n",
    "        return models.Model(encoder_input, [z_mean, z_log_var, z], name = \"encoder\")\n",
    "    \n",
    "    def generate_decoder_model(self, hidden_layers, base_units, kernel_size, strides, dropout_rate):\n",
    "        decoder_input = layers.Input(shape = (self.latent_dims), name = \"decoder_input\")\n",
    "\n",
    "        before_reshape = layers.Dense(np.prod(self.pass_back_shape))(decoder_input)\n",
    "        reshape_layer = layers.Reshape(self.pass_back_shape)(before_reshape)\n",
    "\n",
    "        for i in range(hidden_layers - 1, -1, -1):\n",
    "            conv_transpose_layer = layers.Conv2DTranspose(base_units << i, kernel_size, strides, padding = \"same\")(reshape_layer if i == hidden_layers - 1 else dropout_layer)\n",
    "            batch_norm_layer = layers.BatchNormalization()(conv_transpose_layer)\n",
    "            activation_layer = layers.Activation('relu')(batch_norm_layer)\n",
    "            dropout_layer = layers.Dropout(dropout_rate)(activation_layer)\n",
    "\n",
    "        decoder_output = layers.Conv2DTranspose(13, kernel_size, 1, padding = \"same\")(dropout_layer)\n",
    "        decoder_output_transformed = activations.tanh(decoder_output)\n",
    "\n",
    "        return models.Model(decoder_input, decoder_output_transformed, name = \"decoder\")\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var, z = self.encoder(inputs)\n",
    "        reconstruction = self.decoder(z)\n",
    "        return z_mean, z_log_var, reconstruction\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, reconstruction = self(data)\n",
    "            reconstruction_loss = tf.reduce_mean(losses.binary_crossentropy(data, reconstruction, axis = (1, 2, 3)))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(-0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)), axis = 1))\n",
    "            total_loss = self.beta_1 * reconstruction_loss + self.beta_2 * kl_loss\n",
    "        \n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        return {m.name : m.result() for m in self.metrics}\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        z_mean, z_log_var, reconstruction = self(data)\n",
    "        reconstruction_loss = tf.reduce_mean(losses.binary_crossentropy(data, reconstruction, axis = (1, 2, 3)))\n",
    "        kl_loss = tf.reduce_mean(tf.reduce_sum(-0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)), axis = 1))\n",
    "        total_loss = self.beta_1 * reconstruction_loss + self.beta_2 * kl_loss\n",
    "        \n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        return {m.name : m.result() for m in self.metrics}\n",
    "\n",
    "vae = vae_chess(latent_dims, hidden_layers, base_units, kernel_size, strides, dropout_rate, threshold, beta_1, beta_2)\n",
    "optimiser = optimizers.Adam(learning_rate = learning_rate)\n",
    "vae.compile(optimizer = \"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "497/497 [==============================] - 7s 10ms/step - total_loss: 1194.0696 - reconstruction_loss: 0.1194 - kl_loss: 21.7784 - val_total_loss: 997.3159 - val_reconstruction_loss: 0.0997 - val_kl_loss: 31.3808\n",
      "Epoch 2/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 981.8566 - reconstruction_loss: 0.0982 - kl_loss: 28.4132 - val_total_loss: 966.5741 - val_reconstruction_loss: 0.0966 - val_kl_loss: 29.8279\n",
      "Epoch 3/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 936.7906 - reconstruction_loss: 0.0937 - kl_loss: 27.9320 - val_total_loss: 964.1309 - val_reconstruction_loss: 0.0964 - val_kl_loss: 23.5235\n",
      "Epoch 4/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 936.6564 - reconstruction_loss: 0.0936 - kl_loss: 22.3271 - val_total_loss: 951.6063 - val_reconstruction_loss: 0.0951 - val_kl_loss: 21.5487\n",
      "Epoch 5/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 919.2359 - reconstruction_loss: 0.0919 - kl_loss: 28.3472 - val_total_loss: 914.4094 - val_reconstruction_loss: 0.0914 - val_kl_loss: 34.5904\n",
      "Epoch 6/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 898.5565 - reconstruction_loss: 0.0898 - kl_loss: 30.6729 - val_total_loss: 935.8361 - val_reconstruction_loss: 0.0936 - val_kl_loss: 25.8897\n",
      "Epoch 7/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 902.3751 - reconstruction_loss: 0.0902 - kl_loss: 25.6011 - val_total_loss: 913.6445 - val_reconstruction_loss: 0.0913 - val_kl_loss: 27.7037\n",
      "Epoch 8/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 880.8008 - reconstruction_loss: 0.0881 - kl_loss: 26.4875 - val_total_loss: 921.0838 - val_reconstruction_loss: 0.0921 - val_kl_loss: 23.6338\n",
      "Epoch 9/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 896.8554 - reconstruction_loss: 0.0897 - kl_loss: 21.6485 - val_total_loss: 899.1339 - val_reconstruction_loss: 0.0899 - val_kl_loss: 21.2749\n",
      "Epoch 10/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 910.2593 - reconstruction_loss: 0.0910 - kl_loss: 18.5445 - val_total_loss: 889.2968 - val_reconstruction_loss: 0.0889 - val_kl_loss: 25.8995\n",
      "Epoch 11/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 857.1528 - reconstruction_loss: 0.0857 - kl_loss: 26.8481 - val_total_loss: 873.2368 - val_reconstruction_loss: 0.0873 - val_kl_loss: 27.0746\n",
      "Epoch 12/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 881.0542 - reconstruction_loss: 0.0881 - kl_loss: 23.7595 - val_total_loss: 893.2689 - val_reconstruction_loss: 0.0893 - val_kl_loss: 27.1532\n",
      "Epoch 13/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 856.7868 - reconstruction_loss: 0.0857 - kl_loss: 26.5649 - val_total_loss: 862.4559 - val_reconstruction_loss: 0.0862 - val_kl_loss: 28.5849\n",
      "Epoch 14/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 841.8819 - reconstruction_loss: 0.0842 - kl_loss: 27.6671 - val_total_loss: 869.0917 - val_reconstruction_loss: 0.0869 - val_kl_loss: 31.2134\n",
      "Epoch 15/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 839.7630 - reconstruction_loss: 0.0839 - kl_loss: 29.8120 - val_total_loss: 876.4449 - val_reconstruction_loss: 0.0876 - val_kl_loss: 28.8179\n",
      "Epoch 16/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 850.2514 - reconstruction_loss: 0.0850 - kl_loss: 26.2570 - val_total_loss: 866.9737 - val_reconstruction_loss: 0.0867 - val_kl_loss: 28.4590\n",
      "Epoch 17/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 818.3431 - reconstruction_loss: 0.0818 - kl_loss: 29.8553 - val_total_loss: 857.8770 - val_reconstruction_loss: 0.0858 - val_kl_loss: 29.7051\n",
      "Epoch 18/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 844.0176 - reconstruction_loss: 0.0844 - kl_loss: 25.3719 - val_total_loss: 915.6554 - val_reconstruction_loss: 0.0915 - val_kl_loss: 23.9469\n",
      "Epoch 19/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 838.8419 - reconstruction_loss: 0.0839 - kl_loss: 25.5888 - val_total_loss: 859.1359 - val_reconstruction_loss: 0.0859 - val_kl_loss: 26.6736\n",
      "Epoch 20/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 859.2808 - reconstruction_loss: 0.0859 - kl_loss: 26.9803 - val_total_loss: 869.3715 - val_reconstruction_loss: 0.0869 - val_kl_loss: 27.6262\n",
      "Epoch 21/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 842.6417 - reconstruction_loss: 0.0842 - kl_loss: 27.8605 - val_total_loss: 851.1700 - val_reconstruction_loss: 0.0851 - val_kl_loss: 28.1535\n",
      "Epoch 22/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 845.4847 - reconstruction_loss: 0.0845 - kl_loss: 26.1534 - val_total_loss: 839.3847 - val_reconstruction_loss: 0.0839 - val_kl_loss: 29.0510\n",
      "Epoch 23/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 812.5485 - reconstruction_loss: 0.0812 - kl_loss: 30.2333 - val_total_loss: 888.7922 - val_reconstruction_loss: 0.0889 - val_kl_loss: 27.0992\n",
      "Epoch 24/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 822.6174 - reconstruction_loss: 0.0822 - kl_loss: 30.7418 - val_total_loss: 838.6990 - val_reconstruction_loss: 0.0838 - val_kl_loss: 35.0126\n",
      "Epoch 25/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 824.3907 - reconstruction_loss: 0.0824 - kl_loss: 31.1020 - val_total_loss: 843.7318 - val_reconstruction_loss: 0.0843 - val_kl_loss: 29.7497\n",
      "Epoch 26/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 804.8812 - reconstruction_loss: 0.0805 - kl_loss: 33.5045 - val_total_loss: 816.7246 - val_reconstruction_loss: 0.0816 - val_kl_loss: 36.7929\n",
      "Epoch 27/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 796.0921 - reconstruction_loss: 0.0796 - kl_loss: 35.3161 - val_total_loss: 827.1290 - val_reconstruction_loss: 0.0827 - val_kl_loss: 34.1563\n",
      "Epoch 28/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 815.5811 - reconstruction_loss: 0.0815 - kl_loss: 33.5854 - val_total_loss: 921.2999 - val_reconstruction_loss: 0.0921 - val_kl_loss: 30.8308\n",
      "Epoch 29/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 841.9269 - reconstruction_loss: 0.0842 - kl_loss: 27.8533 - val_total_loss: 825.4949 - val_reconstruction_loss: 0.0825 - val_kl_loss: 30.6706\n",
      "Epoch 30/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 829.8775 - reconstruction_loss: 0.0830 - kl_loss: 29.6382 - val_total_loss: 835.4316 - val_reconstruction_loss: 0.0835 - val_kl_loss: 29.3695\n",
      "Epoch 31/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 886.8113 - reconstruction_loss: 0.0887 - kl_loss: 25.5746 - val_total_loss: 900.6160 - val_reconstruction_loss: 0.0900 - val_kl_loss: 20.9738\n",
      "Epoch 32/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 843.0400 - reconstruction_loss: 0.0843 - kl_loss: 24.2114 - val_total_loss: 969.1140 - val_reconstruction_loss: 0.0969 - val_kl_loss: 28.0886\n",
      "Epoch 33/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 853.6871 - reconstruction_loss: 0.0853 - kl_loss: 24.3835 - val_total_loss: 844.9584 - val_reconstruction_loss: 0.0845 - val_kl_loss: 28.4092\n",
      "Epoch 34/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 810.7253 - reconstruction_loss: 0.0810 - kl_loss: 29.2796 - val_total_loss: 821.9327 - val_reconstruction_loss: 0.0822 - val_kl_loss: 32.1049\n",
      "Epoch 35/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 826.0629 - reconstruction_loss: 0.0826 - kl_loss: 30.6929 - val_total_loss: 826.3717 - val_reconstruction_loss: 0.0826 - val_kl_loss: 31.9380\n",
      "Epoch 36/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 809.0466 - reconstruction_loss: 0.0809 - kl_loss: 31.1738 - val_total_loss: 822.7863 - val_reconstruction_loss: 0.0822 - val_kl_loss: 33.0740\n",
      "Epoch 37/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 808.8225 - reconstruction_loss: 0.0809 - kl_loss: 32.2256 - val_total_loss: 841.0069 - val_reconstruction_loss: 0.0841 - val_kl_loss: 33.2917\n",
      "Epoch 38/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 819.6807 - reconstruction_loss: 0.0819 - kl_loss: 30.1675 - val_total_loss: 822.7017 - val_reconstruction_loss: 0.0822 - val_kl_loss: 29.2954\n",
      "Epoch 39/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 796.9861 - reconstruction_loss: 0.0797 - kl_loss: 31.0890 - val_total_loss: 810.2764 - val_reconstruction_loss: 0.0810 - val_kl_loss: 33.4914\n",
      "Epoch 40/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 790.1567 - reconstruction_loss: 0.0790 - kl_loss: 33.0140 - val_total_loss: 813.2639 - val_reconstruction_loss: 0.0813 - val_kl_loss: 33.2886\n",
      "Epoch 41/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 831.3109 - reconstruction_loss: 0.0831 - kl_loss: 30.2226 - val_total_loss: 849.8211 - val_reconstruction_loss: 0.0850 - val_kl_loss: 30.1448\n",
      "Epoch 42/50\n",
      "497/497 [==============================] - 5s 10ms/step - total_loss: 802.8391 - reconstruction_loss: 0.0803 - kl_loss: 33.3186 - val_total_loss: 808.8881 - val_reconstruction_loss: 0.0809 - val_kl_loss: 35.7427\n",
      "Epoch 43/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 788.7799 - reconstruction_loss: 0.0788 - kl_loss: 34.5539 - val_total_loss: 818.6325 - val_reconstruction_loss: 0.0818 - val_kl_loss: 34.3828\n",
      "Epoch 44/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 820.0709 - reconstruction_loss: 0.0820 - kl_loss: 30.0881 - val_total_loss: 828.4694 - val_reconstruction_loss: 0.0828 - val_kl_loss: 31.2642\n",
      "Epoch 45/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 841.2032 - reconstruction_loss: 0.0841 - kl_loss: 30.8706 - val_total_loss: 825.1193 - val_reconstruction_loss: 0.0825 - val_kl_loss: 33.3033\n",
      "Epoch 46/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 822.5002 - reconstruction_loss: 0.0822 - kl_loss: 29.1917 - val_total_loss: 828.2065 - val_reconstruction_loss: 0.0828 - val_kl_loss: 29.6875\n",
      "Epoch 47/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 818.9307 - reconstruction_loss: 0.0819 - kl_loss: 30.1345 - val_total_loss: 820.7463 - val_reconstruction_loss: 0.0820 - val_kl_loss: 33.7879\n",
      "Epoch 48/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 800.3334 - reconstruction_loss: 0.0800 - kl_loss: 34.1284 - val_total_loss: 813.4551 - val_reconstruction_loss: 0.0813 - val_kl_loss: 37.4703\n",
      "Epoch 49/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 783.2660 - reconstruction_loss: 0.0783 - kl_loss: 37.1216 - val_total_loss: 804.9252 - val_reconstruction_loss: 0.0805 - val_kl_loss: 38.2346\n",
      "Epoch 50/50\n",
      "497/497 [==============================] - 5s 9ms/step - total_loss: 790.0439 - reconstruction_loss: 0.0790 - kl_loss: 37.1644 - val_total_loss: 842.0956 - val_reconstruction_loss: 0.0842 - val_kl_loss: 33.4221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22ab6fc10>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "vae.fit(data, epochs = EPOCHS, batch_size = BATCH_SIZE, shuffle = True, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_board(tensor):\n",
    "    board = [['.' for j in range(8)] for i in range(8)]\n",
    "    for i, p in enumerate('KQRBNPkqrbnp'):\n",
    "        for r in range(8):\n",
    "            for c in range(8):\n",
    "                if tensor[r][c][i] > 0.4:\n",
    "                    if board[r][c] != '.':\n",
    "                        print(f'conflict between {board[r][c]} and {p} at position ({r},{c})')\n",
    "                        continue\n",
    "                    board[r][c] = p\n",
    "    pprint.pprint(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['r', 'n', 'b', 'q', 'k', 'b', '.', 'r'],\n",
      " ['p', 'p', '.', 'p', '.', 'p', 'p', 'p'],\n",
      " ['.', '.', '.', '.', '.', 'P', '.', '.'],\n",
      " ['.', '.', '.', '.', '.', '.', '.', '.'],\n",
      " ['.', '.', '.', '.', '.', '.', '.', '.'],\n",
      " ['.', '.', '.', '.', '.', '.', '.', '.'],\n",
      " ['.', '.', '.', '.', '.', '.', 'P', 'P'],\n",
      " ['.', '.', '.', '.', '.', 'R', 'K', '.']]\n",
      "\n",
      "[['r', '.', 'b', 'q', '.', 'r', 'k', '.'],\n",
      " ['p', 'p', 'p', '.', '.', 'p', '.', 'p'],\n",
      " ['.', '.', '.', '.', 'p', '.', 'p', '.'],\n",
      " ['.', '.', '.', 'p', '.', '.', '.', '.'],\n",
      " ['.', '.', '.', 'P', '.', '.', '.', '.'],\n",
      " ['.', '.', 'P', '.', '.', 'N', '.', '.'],\n",
      " ['P', 'P', '.', '.', '.', 'P', 'P', '.'],\n",
      " ['R', '.', '.', 'Q', '.', '.', 'K', 'R']]\n",
      "\n",
      "[['r', 'n', 'b', 'q', '.', 'r', 'k', '.'],\n",
      " ['p', 'p', 'p', 'p', '.', 'p', 'p', 'p'],\n",
      " ['.', '.', '.', '.', '.', '.', '.', '.'],\n",
      " ['.', '.', '.', '.', '.', '.', '.', '.'],\n",
      " ['.', '.', '.', '.', '.', '.', '.', '.'],\n",
      " ['.', '.', '.', '.', '.', '.', '.', '.'],\n",
      " ['P', 'P', 'P', 'P', '.', 'P', 'P', 'P'],\n",
      " ['R', '.', 'B', 'Q', '.', 'R', 'K', '.']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for reconstruction in vae.decoder(tf.random.truncated_normal(shape = (3, latent_dims))):\n",
    "    print_board(reconstruction)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
